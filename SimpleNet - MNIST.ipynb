{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Простая сеть на pytorch для распознования рукописных букв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as tfs\n",
    "from PIL import Image, ImageFile\n",
    "from torchvision.datasets import MNIST\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "from torch.nn.functional import cross_entropy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfs = tfs.Compose([tfs.ToTensor(), tfs.Normalize((0.5),(0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './'\n",
    "train = MNIST(root, train=True, transform=data_tfs, download=True)\n",
    "test = MNIST(root, train=False, transform=data_tfs, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Data size:\\n\\t train {len(train)}, test {len(test)}')\n",
    "print(f'Data shape:\\n\\t features {train[0][0].shape},\\n\\t target {type(test[0][1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, drop_last=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(iter(train_loader))\n",
    "x_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 784\n",
    "classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.FloatTensor(features, classes).uniform_(-1,1) / features**0.5\n",
    "W.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "lr = 1e-2\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.reshape(x_batch.shape[0], -1)\n",
    "        y_batch = y_batch\n",
    "        \n",
    "        logits = x_batch @ W\n",
    "        probabilities = torch.exp(logits) / torch.exp(logits).sum(dim=1, keepdims=True)\n",
    "        \n",
    "        loss = -torch.log(probabilities[range(batch_size), y_batch]).mean()\n",
    "        history.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        grad = W.grad\n",
    "        with torch.no_grad():\n",
    "            W -= lr * grad\n",
    "        W.grad.zero_()\n",
    "        \n",
    "print(f'{i+1},\\t loss: {history[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(history)\n",
    "plt.title('Loss by batch iterations')\n",
    "plt.ylabel('Entropy Loss')\n",
    "plt.xlabel('batches')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "batches = 0\n",
    "\n",
    "for x_batch, y_batch in test_loader:\n",
    "    batches += 1\n",
    "    x_batch = x_batch.view(x_batch.shape[0], -1)\n",
    "    y_batch = y_batch\n",
    "    \n",
    "    preds = torch.argmax(x_batch @ W, dim=1)\n",
    "    acc += (preds == y_batch).cpu().numpy().mean()\n",
    "print(f'Test accuracy {acc / batches: .3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
